{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cad75a1-b852-4bd3-9299-d046846ac7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "setup.init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed27990b-b5a5-43bb-a27b-16e7fc044e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from market import services as market_services\n",
    "from market import tasks as market_tasks\n",
    "from market.models import Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd7fafa-e2b9-49e2-8400-3de272b8b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from decouple import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753f9e85-20c6-45f3-803e-5c89a5c36489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"AAPL\"\n",
    "name = \"Apple\"\n",
    "company, _ = Company.objects.get_or_create(name=name, ticker=ticker)\n",
    "company.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e371fe-876c-4003-be3a-e7d4366380a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical sync days ago 30\n",
      "dataset length 3398\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "30 done\n",
      "\n",
      "Historical sync days ago 60\n",
      "dataset length 6730\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "60 done\n",
      "\n",
      "Historical sync days ago 90\n",
      "dataset length 10788\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "90 done\n",
      "\n",
      "Historical sync days ago 120\n",
      "dataset length 12700\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "120 done\n",
      "\n",
      "Historical sync days ago 150\n",
      "dataset length 12669\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "150 done\n",
      "\n",
      "Historical sync days ago 180\n",
      "dataset length 12446\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "180 done\n",
      "\n",
      "Historical sync days ago 210\n",
      "dataset length 12279\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "210 done\n",
      "\n",
      "Historical sync days ago 240\n",
      "dataset length 12131\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "240 done\n",
      "\n",
      "Historical sync days ago 270\n",
      "dataset length 12135\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "270 done\n",
      "\n",
      "Historical sync days ago 300\n",
      "dataset length 12161\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "300 done\n",
      "\n",
      "Historical sync days ago 330\n",
      "dataset length 12176\n",
      "Doing chunk 0\n",
      "finished chunk 0\n",
      "Doing chunk 1000\n",
      "finished chunk 1000\n",
      "Doing chunk 2000\n",
      "finished chunk 2000\n",
      "Doing chunk 3000\n",
      "finished chunk 3000\n",
      "Doing chunk 4000\n",
      "finished chunk 4000\n",
      "Doing chunk 5000\n",
      "finished chunk 5000\n",
      "Doing chunk 6000\n",
      "finished chunk 6000\n",
      "Doing chunk 7000\n",
      "finished chunk 7000\n",
      "Doing chunk 8000\n",
      "finished chunk 8000\n",
      "Doing chunk 9000\n",
      "finished chunk 9000\n",
      "Doing chunk 10000\n",
      "finished chunk 10000\n",
      "Doing chunk 11000\n",
      "finished chunk 11000\n",
      "Doing chunk 12000\n",
      "finished chunk 12000\n",
      "330 done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "market_tasks.sync_historical_stock_data(years_ago=1, company_ids=[company.id], use_celery=False, verbose=True)\n",
    "\n",
    "# use celery / async\n",
    "# market_tasks.sync_historical_stock_data.delay(years_ago=5, company_ids=[company.id], use_celery=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45edca03-e0b4-40db-b8ea-3f795d1faf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': -1,\n",
       " 'ticker': 'AAPL',\n",
       " 'indicators': {'ma_5': 235.318,\n",
       "  'ma_20': 245.604,\n",
       "  'current_price': 233.78,\n",
       "  'conservative_target': 248.1088,\n",
       "  'aggressive_target': 256.9612,\n",
       "  'average_price': 238.0477,\n",
       "  'avg_volume': 2879.7123287671234,\n",
       "  'latest_volume': 603,\n",
       "  'volume_change_percent': -79.06040843120745,\n",
       "  'rsi': 47.4629,\n",
       "  'avg_gain': 0.9259,\n",
       "  'avg_loss': 1.0249,\n",
       "  'period': 14,\n",
       "  'days': 90}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = market_services.get_stock_indicators(ticker=ticker, days=90)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e79e4df-5f44-4d13-b0fa-5915a371c91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"score\": -1, \"ticker\": \"AAPL\", \"indicators\": {\"ma_5\": 235.318, \"ma_20\": 245.604, \"current_price\": 233.78, \"conservative_target\": 248.1088, \"aggressive_target\": 256.9612, \"average_price\": 238.0477, \"avg_volume\": 2879.7123287671234, \"latest_volume\": 603, \"volume_change_percent\": -79.06040843120745, \"rsi\": 47.4629, \"avg_gain\": 0.9259, \"avg_loss\": 1.0249, \"period\": 14, \"days\": 90}}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_as_json = json.dumps(results)\n",
    "results_as_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb35fc7d-b159-4972-b186-d073421d2834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/harry/StockTradingbot\n",
      "Files in Current Directory: ['.env.sample', 'nbs', 'src', '.idea', '.gitignore', 'README.md', 'myenv', 'compose.yaml', 'requirements.txt', '.env', '.git']\n"
     ]
    }
   ],
   "source": [
    "from decouple import config, AutoConfig\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "print(\"Files in Current Directory:\", os.listdir(os.getcwd()))\n",
    "config = AutoConfig(search_path=\"/home/harry/StockTradingbot\") \n",
    "\n",
    "DEEPSEEK_API_KEY = config(\"DEEPSEEK_API_KEY\", default=None)\n",
    "\n",
    "assert DEEPSEEK_API_KEY is not None, \"DEEPSEEK_API_KEY is not set in the .env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45a400-dd1e-4ec6-b9f8-9a9f4e005ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you have OpenAI API Key:\n",
    "'''\n",
    "OPENAI_API_KEY=config(\"OPENAI_API_KEY\", default=None)\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert an analyzing stocks and respond in JSON data\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Considering these results {results_as_json}, provide a recommendation\"}\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"recommendation\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"buy\": {\n",
    "                        \"description\": \"Recommend to buy stock\",\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"sell\": {\n",
    "                        \"description\": \"Recommend to sell stock\",\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"hold\": {\n",
    "                        \"description\": \"Recommend to hold stock\",\n",
    "                        \"type\": \"boolean\"\n",
    "                    },\n",
    "                    \"explanation\": {\n",
    "                        \"description\": \"Explanation of reasoning in 1 or 2 sentences\",\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "result = json.loads(response.choices[0].message.content)\n",
    "result\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e287cfa-0100-4763-bb2c-598ce0e9ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for DeepSeek Api\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert at analyzing stocks and respond in JSON data\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Considering these results {results_as_json}, provide a recommendation\"}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},  # Use \"json_object\" instead of \"json_schema\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a4d22-1e58-4eaa-9036-33f9579f22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.loads(response.choices[0].message.content)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb7112a-8bf6-4b07-af3f-f289ac499bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get('hold') is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b0a486-a15d-43fa-b1fc-4f1876c15bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR LOGIC BASED RECOMMENDER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f43f2c6f-beb8-4126-916e-c6f6eb2ee1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "days = 90\n",
    "queryset = market_services.get_daily_stock_quotes_queryset(ticker, days=days)\n",
    "averages = market_services.get_daily_moving_averages(ticker, days=days, queryset=queryset)\n",
    "price_target = market_services.get_price_target(ticker, days=days, queryset=queryset)\n",
    "volume_trend = market_services.get_volume_trend(ticker, days=days, queryset=queryset)\n",
    "rsi_data = market_services.calculate_rsi(ticker, days=days, period=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1e8486-d87b-4ab3-9fa6-312b992555d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current_price': 233.78,\n",
       " 'conservative_target': 248.1088,\n",
       " 'aggressive_target': 256.9612,\n",
       " 'average_price': 238.0477}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9127db-ec19-4b43-aa05-f81c8fb68d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13a4cc3c-9bbe-4109-bc72-6812a2b384de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if averages.get('ma_5') > averages.get('ma_20'):\n",
    "    signals.append(1)\n",
    "else:\n",
    "    signals.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a75a45-7485-401e-8caf-06e50baed704",
   "metadata": {},
   "outputs": [],
   "source": [
    "if price_target.get('current_price') < price_target.get('conservative_target'):\n",
    "    signals.append(1)\n",
    "else:\n",
    "    signals.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e8c44b-0102-4a8d-908b-079ee70a849b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_volume': 2879.7123287671234,\n",
       " 'latest_volume': 603,\n",
       " 'volume_change_percent': -79.06040843120745}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03ae5587-c192-45eb-ae83-350f46b1d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if volume_trend.get(\"volume_change_percent\") > 20:\n",
    "    signals.append(1)\n",
    "elif volume_trend.get(\"volume_change_percent\") < -20:\n",
    "    signals.append(-1)\n",
    "else:\n",
    "    signals.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b20cad-8b99-4e17-99fa-03f334057efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rsi': 47.4629,\n",
       " 'avg_gain': 0.9259,\n",
       " 'avg_loss': 1.0249,\n",
       " 'period': 14,\n",
       " 'days': 90}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa0ce1bc-0768-438a-93d9-2012f2638ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi = rsi_data.get('rsi')\n",
    "if rsi > 70:\n",
    "    signals.append(-1)  # Overbought\n",
    "elif rsi < 30:\n",
    "    signals.append(1) # Oversold\n",
    "else:\n",
    "    signals.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "987b004c-5d21-4d2c-93be-ddca343b3522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sum(signals)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df923fd6-b91f-4c5d-9aa6-535f7c99bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLD\n"
     ]
    }
   ],
   "source": [
    "if score>= 2:\n",
    "    print(\"BUY\")\n",
    "elif score <= -2:\n",
    "    print(\"SELL\")\n",
    "else:\n",
    "    print(\"HOLD\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
