{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2480a98-08bb-4d6f-9200-d4638cf80895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import mplfinance as mpf\n",
    "import matplotlib.dates as mdates\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import mplcursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a648c55-7396-4a9e-a28c-cec50d62e53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation successful!\n",
      "Sample training data:\n",
      "Price            Close        RSI       MACD  regression_5d  target\n",
      "Date                                                               \n",
      "2024-12-24  462.279999  68.422829  34.480358       3.872998       2\n",
      "2024-12-26  454.130005  65.645587  34.011526       7.713998       2\n",
      "2024-12-27  431.660004  58.585163  31.464133       4.473001       2\n",
      "2024-12-30  417.410004  54.576261  27.972995      -5.700000       2\n",
      "2024-12-31  403.839996  50.997470  23.836484     -15.360001       2\n",
      "\n",
      "Training Data: 2241 rows\n",
      "Backtesting Data: 502 rows\n"
     ]
    }
   ],
   "source": [
    "TICKER = 'TSLA'\n",
    "\n",
    "def prepare_data():\n",
    "    stock_data = yf.download(TICKER, start='2014-01-01', end='2025-01-01')\n",
    "    df = stock_data.copy()\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    df = df.rename(columns={'Vol': 'Volume'})\n",
    "\n",
    "    # Calculate a normalized price metric\n",
    "    df['normalized'] = (df['Close'] - df['Low']) / ((df['High'] - df['Low']).replace(0, np.nan)).fillna(0.5)\n",
    "\n",
    "    # Function to calculate regression slope\n",
    "    def calculate_slope(series):\n",
    "        return np.polyfit(np.arange(len(series)), series, 1)[0] if len(series) > 1 else np.nan\n",
    "\n",
    "    windows = [3, 5, 10, 20]\n",
    "    for w in windows:\n",
    "        df[f'regression_{w}d'] = df['Close'].rolling(window=w, min_periods=2).apply(calculate_slope, raw=True)\n",
    "\n",
    "    # Technical Indicators\n",
    "    df['RSI'] = RSIIndicator(df['Close'], window=14).rsi()\n",
    "    macd = MACD(df['Close'])\n",
    "    df['MACD'] = macd.macd()\n",
    "    df['MACD_signal'] = macd.macd_signal()\n",
    "    df['Volatility'] = df['Close'].pct_change().rolling(5).std()\n",
    "\n",
    "    # Identify local extrema for target signals\n",
    "    local_min = argrelextrema(df['Close'].values, np.less, order=5)[0]\n",
    "    local_max = argrelextrema(df['Close'].values, np.greater, order=5)[0]\n",
    "\n",
    "    # Create target column for training:\n",
    "    #   0 -> Buy signal, 1 -> Sell signal, 2 -> Natural (default)\n",
    "    df['target'] = 2  # assign natural as the default\n",
    "    df.iloc[local_min, df.columns.get_loc('target')] = 0  # Buy signal\n",
    "    df.iloc[local_max, df.columns.get_loc('target')] = 1  # Sell signal\n",
    "\n",
    "    # Define features to be used in the model\n",
    "    features = ['normalized', 'Volume', 'RSI', 'MACD', 'Volatility'] + [f'regression_{w}d' for w in windows]\n",
    "\n",
    "    # For backtesting, drop rows with missing features.\n",
    "    df_features = df.dropna(subset=features).copy()\n",
    "\n",
    "    # For training, drop rows missing features (target is always present now)\n",
    "    model_df = df.dropna(subset=features).copy()\n",
    "\n",
    "    # Ensure data is sorted by date (important for time series)\n",
    "    df_features.sort_index(inplace=True)\n",
    "    model_df.sort_index(inplace=True)\n",
    "    return df_features, model_df\n",
    "\n",
    "try:\n",
    "    df_features, model_df = prepare_data()\n",
    "    print(\"Data preparation successful!\")\n",
    "    print(\"Sample training data:\")\n",
    "    print(model_df[['Close', 'RSI', 'MACD', 'regression_5d', 'target']].tail())\n",
    "except Exception as e:\n",
    "    print(f\"Data error: {str(e)}\")\n",
    "\n",
    "# Split training data (from model_df) into train and test based on date.\n",
    "train_df = model_df[model_df.index < '2023-01-01'].copy()\n",
    "# For backtesting, use all available data after 2023 from df_features.\n",
    "test_df  = df_features[df_features.index >= '2023-01-01'].copy()\n",
    "\n",
    "print(f\"\\nTraining Data: {train_df.shape[0]} rows\")\n",
    "print(f\"Backtesting Data: {test_df.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882377c9-f076-4a85-bf48-fe109c2e5e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom class weights being used: {0: 5.976, 1: 5.574626865671642, 2: 0.1884460141271443}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'StackingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 142\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_model, model_df, features, fold_metrics \n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Train on the training set only.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# (Make sure 'train_df' has been prepared as per your earlier data preparation cell.)\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m model, _, features, fold_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model_df, decision_threshold)\u001b[0m\n\u001b[1;32m     63\u001b[0m final_estimator \u001b[38;5;241m=\u001b[39m LogisticRegression(\n\u001b[1;32m     64\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39mcustom_class_weight,\n\u001b[1;32m     65\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     66\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# --- Build the StackingClassifier ---\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m stacking_clf \u001b[38;5;241m=\u001b[39m \u001b[43mStackingClassifier\u001b[49m(\n\u001b[1;32m     70\u001b[0m     estimators\u001b[38;5;241m=\u001b[39mbase_estimators,\n\u001b[1;32m     71\u001b[0m     final_estimator\u001b[38;5;241m=\u001b[39mfinal_estimator,\n\u001b[1;32m     72\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,            \u001b[38;5;66;03m# internal CV for stacking (you can adjust this)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     74\u001b[0m     passthrough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# set to True if you want the meta-model to receive original features too.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# --- Time Series Cross-Validation with Threshold Tuning ---\u001b[39;00m\n\u001b[1;32m     78\u001b[0m tscv \u001b[38;5;241m=\u001b[39m TimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StackingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "def custom_predict(model, X, decision_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Use the predicted probabilities to apply threshold tuning.\n",
    "    \n",
    "    For each sample, if the probability of class 0 (buy) or class 1 (sell)\n",
    "    exceeds the decision_threshold, assign the label with the highest probability among these.\n",
    "    Otherwise, assign class 2 (natural).\n",
    "    \n",
    "    Note: This assumes that model.classes_ is sorted as [0, 1, 2].\n",
    "    \"\"\"\n",
    "    proba = model.predict_proba(X)\n",
    "    preds = []\n",
    "    for p in proba:\n",
    "        # p[0]: probability for class 0 (buy)\n",
    "        # p[1]: probability for class 1 (sell)\n",
    "        # p[2]: probability for class 2 (natural)\n",
    "        if p[0] >= decision_threshold or p[1] >= decision_threshold:\n",
    "            # If at least one of the buy/sell probabilities is high enough, choose the higher of the two.\n",
    "            preds.append(0 if p[0] >= p[1] else 1)\n",
    "        else:\n",
    "            preds.append(2)\n",
    "    return np.array(preds)\n",
    "\n",
    "def train_model(model_df, decision_threshold=0.3):\n",
    "    features = ['normalized', 'Volume', 'RSI', 'MACD', 'Volatility',\n",
    "                'regression_3d', 'regression_5d', 'regression_10d', 'regression_20d']\n",
    "    \n",
    "    missing = [f for f in features if f not in model_df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing features: {missing}\")\n",
    "    \n",
    "    X = model_df[features]\n",
    "    y = model_df['target'].astype(int)\n",
    "    \n",
    "    # --- Cost-Sensitive Learning: Compute balanced class weights ---\n",
    "    unique_classes = np.unique(y)\n",
    "    balanced_weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=y)\n",
    "    custom_class_weight = dict(zip(unique_classes, balanced_weights))\n",
    "    # Further reduce the weight for class 2 (natural) since it's over-represented.\n",
    "    if 2 in custom_class_weight:\n",
    "        custom_class_weight[2] *= 0.5\n",
    "\n",
    "    print(\"Custom class weights being used:\", custom_class_weight)\n",
    "    \n",
    "    # --- Define base estimators with cost-sensitive parameters ---\n",
    "    base_estimators = [\n",
    "        ('rf', RandomForestClassifier(\n",
    "                n_estimators=200,\n",
    "                class_weight=custom_class_weight,\n",
    "                max_depth=5,\n",
    "                random_state=42)),\n",
    "        ('svc', SVC(\n",
    "                probability=True,\n",
    "                class_weight=custom_class_weight,\n",
    "                random_state=42)),\n",
    "        ('lr', LogisticRegression(\n",
    "                class_weight=custom_class_weight,\n",
    "                max_iter=1000,\n",
    "                random_state=42))\n",
    "    ]\n",
    "    \n",
    "    # --- Define the final estimator for stacking ---\n",
    "    final_estimator = LogisticRegression(\n",
    "        class_weight=custom_class_weight,\n",
    "        max_iter=1000,\n",
    "        random_state=42)\n",
    "    \n",
    "    # --- Build the StackingClassifier ---\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=final_estimator,\n",
    "        cv=5,            # internal CV for stacking (you can adjust this)\n",
    "        n_jobs=-1,\n",
    "        passthrough=False  # set to True if you want the meta-model to receive original features too.\n",
    "    )\n",
    "    \n",
    "    # --- Time Series Cross-Validation with Threshold Tuning ---\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    fold_metrics = []\n",
    "    \n",
    "    print(\"\\nStarting 5-Fold Time Series Cross-Validation with Threshold Tuning:\\n\")\n",
    "    for fold, (train_idx, valid_idx) in enumerate(tscv.split(X)):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        \n",
    "        # Fit the stacking classifier on the training fold.\n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Instead of default predict, use our custom threshold-based prediction.\n",
    "        y_pred = custom_predict(stacking_clf, X_valid, decision_threshold=decision_threshold)\n",
    "        \n",
    "        # Gather metrics.\n",
    "        report_dict = classification_report(y_valid, y_pred, output_dict=True, zero_division=0)\n",
    "        accuracy = accuracy_score(y_valid, y_pred)\n",
    "        confusion = confusion_matrix(y_valid, y_pred)\n",
    "        \n",
    "        fold_metrics.append({\n",
    "            'fold': fold,\n",
    "            'accuracy': accuracy,\n",
    "            'report': report_dict,\n",
    "            'confusion': confusion\n",
    "        })\n",
    "        \n",
    "        # Print out metrics for the current fold.\n",
    "        print(f\"Fold {fold + 1} Metrics:\")\n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        for cls in ['0', '1', '2']:\n",
    "            if cls in report_dict:\n",
    "                precision = report_dict[cls]['precision']\n",
    "                recall = report_dict[cls]['recall']\n",
    "                f1 = report_dict[cls]['f1-score']\n",
    "                support = report_dict[cls]['support']\n",
    "                print(f\"  Class {cls} -- Precision: {precision:.3f}, Recall: {recall:.3f}, F1-Score: {f1:.3f}, Support: {support}\")\n",
    "        print(\"Macro Avg --\",\n",
    "              f\"Precision: {report_dict['macro avg']['precision']:.3f},\",\n",
    "              f\"Recall: {report_dict['macro avg']['recall']:.3f},\",\n",
    "              f\"F1-Score: {report_dict['macro avg']['f1-score']:.3f}\")\n",
    "        print(\"Weighted Avg --\",\n",
    "              f\"Precision: {report_dict['weighted avg']['precision']:.3f},\",\n",
    "              f\"Recall: {report_dict['weighted avg']['recall']:.3f},\",\n",
    "              f\"F1-Score: {report_dict['weighted avg']['f1-score']:.3f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion)\n",
    "        print(\"-\" * 50, \"\\n\")\n",
    "    \n",
    "    # --- Train Final Model on the Entire Training Set ---\n",
    "    final_model = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=final_estimator,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        passthrough=False\n",
    "    )\n",
    "    final_model.fit(X, y)\n",
    "    \n",
    "    # Note: You can also wrap the final_model's predict with custom_predict if you wish to use threshold tuning at test time.\n",
    "    \n",
    "    return final_model, model_df, features, fold_metrics \n",
    "\n",
    "# Train on the training set only.\n",
    "# (Make sure 'train_df' has been prepared as per your earlier data preparation cell.)\n",
    "model, _, features, fold_metrics = train_model(train_df, decision_threshold=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b223b-dccf-4157-a8d8-e5ec7e5d8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtester:\n",
    "    def __init__(self, initial_balance=3000):\n",
    "        self.initial_balance = initial_balance\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.cash = self.initial_balance\n",
    "        self.shares = 0\n",
    "        self.trades = []\n",
    "        self.portfolio = [self.initial_balance]\n",
    "        self.peak = self.initial_balance\n",
    "        self.drawdown = 0\n",
    "        self.drawdown_history = [] \n",
    "        \n",
    "    def run(self, data, model, features, threshold=0.4):\n",
    "        self.reset()\n",
    "        data = data.copy()\n",
    "        \n",
    "        data['pred_proba'] = model.predict_proba(data[features])[:, 1]\n",
    "        data['signal'] = (data['pred_proba'] > threshold).astype(int)\n",
    "        \n",
    "        for idx, row in data.iterrows():\n",
    "            current_value = self.cash + self.shares * row['Close']\n",
    "            self.portfolio.append(current_value)\n",
    "            \n",
    "            self.peak = max(self.peak, current_value)\n",
    "            current_drawdown = (self.peak - current_value)/self.peak\n",
    "            self.drawdown = max(self.drawdown, current_drawdown)\n",
    "            self.drawdown_history.append(current_drawdown)\n",
    "            \n",
    "            if self.shares == 0 and row['signal'] == 0:\n",
    "                # Buy\n",
    "                self.shares = self.cash / row['Close']\n",
    "                self.cash = 0\n",
    "                self.trades.append({'type': 'buy', 'date': idx, 'price': row['Close']})\n",
    "                \n",
    "            elif self.shares > 0 and row['signal'] == 1:\n",
    "                # Sell\n",
    "                self.cash = self.shares * row['Close']\n",
    "                self.shares = 0\n",
    "                self.trades.append({\n",
    "                    'type': 'sell',\n",
    "                    'date': idx,\n",
    "                    'price': row['Close'],\n",
    "                    'profit': self.cash - self.initial_balance\n",
    "                })\n",
    "        \n",
    "        return self.trades, self.portfolio[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4941579-3ddd-4e79-b9ef-b46dd2ec22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "def plot_strategy_analysis(name, trades, portfolio, drawdowns, data, initial_balance):\n",
    "    # Filter test data (example: from 2023-01-01 onward)\n",
    "    test_data = data[data.index >= '2023-01-01']\n",
    "    buy_dates = [t['date'] for t in trades if t['type'] == 'buy']\n",
    "    sell_dates = [t['date'] for t in trades if t['type'] == 'sell']\n",
    "    \n",
    "    # Create a figure with an 8-row x 2-column grid.\n",
    "    # Increase the height ratio for the candlestick chart by setting a higher value in the first row.\n",
    "    fig = plt.figure(figsize=(18, 20))\n",
    "    # Here, row 0 is for the candlestick chart. We set its ratio to 5 (instead of 3) to make it much larger.\n",
    "    gs = gridspec.GridSpec(8, 2, height_ratios=[5, 2, 1, 1, 1, 1, 1, 1])\n",
    "    \n",
    "    # --- (1) Candlestick Chart with Trading Signals (Much Bigger) ---\n",
    "    ax1 = plt.subplot(gs[0, :])\n",
    "    \n",
    "    # Prepare OHLC data (reset_index so that Date becomes a column)\n",
    "    ohlc_data = test_data[['Open', 'High', 'Low', 'Close']].reset_index()\n",
    "    # Convert dates to matplotlib's internal date format\n",
    "    ohlc_data['Date'] = ohlc_data['Date'].map(mdates.date2num)\n",
    "    \n",
    "    # Plot candlesticks using mplfinance's original flavor\n",
    "    candlestick_ohlc(\n",
    "        ax1, \n",
    "        ohlc_data[['Date', 'Open', 'High', 'Low', 'Close']].values,\n",
    "        width=0.6,\n",
    "        colorup='#2ecc71',    # Green for up days\n",
    "        colordown='#e74c3c',  # Red for down days\n",
    "        alpha=0.8\n",
    "    )\n",
    "    \n",
    "    # Add buy signals as shaded regions and markers\n",
    "    for bd in buy_dates:\n",
    "        ax1.axvspan(mdates.date2num(bd - pd.Timedelta(hours=12)), \n",
    "                    mdates.date2num(bd + pd.Timedelta(hours=12)), \n",
    "                    facecolor='#2ecc71', alpha=0.15)\n",
    "    ax1.scatter([mdates.date2num(d) for d in buy_dates], \n",
    "                test_data.loc[buy_dates, 'Close'],\n",
    "                marker='^', color='#27ae60', s=130, edgecolors='white',\n",
    "                linewidth=1.5, label='Buy Signal', zorder=3)\n",
    "    \n",
    "    # Add sell signals as markers\n",
    "    ax1.scatter([mdates.date2num(d) for d in sell_dates], \n",
    "                test_data.loc[sell_dates, 'Close'],\n",
    "                marker='v', color='#c0392b', s=130, edgecolors='white',\n",
    "                linewidth=1.5, label='Sell Signal', zorder=3)\n",
    "    \n",
    "    # Format the x-axis with dates\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    ax1.set_title(f'{name} - Candlestick Chart with Trading Signals', fontsize=16, pad=20)\n",
    "    ax1.set_ylabel('Price (USD)', fontsize=14)\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax1.grid(alpha=0.25)\n",
    "    \n",
    "    # Add interactive hover for candlestick chart\n",
    "    mplcursors.cursor(ax1, hover=True)\n",
    "    \n",
    "    # --- (2) Price Line Chart with Trading Signals (Line in White) ---\n",
    "    ax2 = plt.subplot(gs[1, :])\n",
    "    ax2.plot(test_data.index, test_data['Close'], color='white', lw=1.5, label='Price')\n",
    "    \n",
    "    for bd in buy_dates:\n",
    "        ax2.axvspan(bd - pd.Timedelta(hours=12), bd + pd.Timedelta(hours=12), \n",
    "                    facecolor='lime', alpha=0.2)\n",
    "    ax2.scatter(buy_dates, test_data.loc[buy_dates, 'Close'], \n",
    "                marker='^', color='darkgreen', s=120, edgecolors='white', \n",
    "                linewidth=1, label='Buy', zorder=3)\n",
    "    ax2.scatter(sell_dates, test_data.loc[sell_dates, 'Close'],\n",
    "                marker='v', color='maroon', s=120, edgecolors='white', \n",
    "                linewidth=1, label='Sell', zorder=3)\n",
    "    ax2.set_title(f'{name} - Price with Trading Signals (Line Chart)', fontsize=14)\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # Add interactive hover for line chart\n",
    "    mplcursors.cursor(ax2, hover=True)\n",
    "    \n",
    "    # --- (3) Win/Loss Trade Outcomes ---\n",
    "    ax3 = plt.subplot(gs[2, :])\n",
    "    win_dates = [t['date'] for t in trades if t['type'] == 'sell' and t.get('profit', 0) > 0]\n",
    "    loss_dates = [t['date'] for t in trades if t['type'] == 'sell' and t.get('profit', 0) <= 0]\n",
    "    \n",
    "    ax3.plot(test_data.index, test_data['Close'], color='gray', alpha=0.4, label='Price')\n",
    "    ax3.scatter(win_dates, test_data.loc[win_dates, 'Close'], \n",
    "                color='lime', s=50, label='Win')\n",
    "    ax3.scatter(loss_dates, test_data.loc[loss_dates, 'Close'],\n",
    "                color='red', s=50, label='Loss')\n",
    "    ax3.set_title('Win/Loss Trade Outcomes', fontsize=12)\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # --- (4) MACD Indicator ---\n",
    "    ax4 = plt.subplot(gs[3, :])\n",
    "    ax4.plot(test_data.index, test_data['MACD'], label='MACD', color='blue')\n",
    "    ax4.plot(test_data.index, test_data['MACD_signal'], label='Signal', color='orange')\n",
    "    ax4.axhline(0, color='grey', ls='--', alpha=0.5)\n",
    "    ax4.set_title('MACD', fontsize=12)\n",
    "    ax4.legend()\n",
    "    ax4.grid(alpha=0.3)\n",
    "    \n",
    "    # --- (5) RSI ---\n",
    "    ax5 = plt.subplot(gs[4, :])\n",
    "    ax5.plot(test_data.index, test_data['RSI'], color='purple')\n",
    "    ax5.axhline(30, color='red', ls='--', alpha=0.7)\n",
    "    ax5.axhline(70, color='red', ls='--', alpha=0.7)\n",
    "    ax5.set_ylim(0, 100)\n",
    "    ax5.set_title('RSI', fontsize=12)\n",
    "    ax5.grid(alpha=0.3)\n",
    "    \n",
    "    # --- (6) Portfolio Value and Drawdown ---\n",
    "    ax6 = plt.subplot(gs[5, 0])\n",
    "    ax6.plot(portfolio, color='#27ae60', lw=1.5)\n",
    "    ax6.set_title('Portfolio Value', fontsize=12)\n",
    "    ax6.grid(alpha=0.3)\n",
    "    \n",
    "    ax7 = plt.subplot(gs[5, 1])\n",
    "    ax7.plot([d * 100 for d in drawdowns], color='#c0392b', lw=1.2)\n",
    "    ax7.set_title('Drawdown (%)', fontsize=12)\n",
    "    ax7.grid(alpha=0.3)\n",
    "    \n",
    "    # --- (7) Win/Loss Pie Chart ---\n",
    "    ax8 = plt.subplot(gs[6, 0])\n",
    "    profits = [t.get('profit', 0) for t in trades if t['type'] == 'sell']\n",
    "    win_rate = sum(p > 0 for p in profits) / len(profits) if profits else 0\n",
    "    ax8.pie([win_rate, 1 - win_rate], labels=['Win', 'Loss'],\n",
    "            colors=['#2ecc71', '#e74c3c'], autopct='%1.1f%%', startangle=90,\n",
    "            wedgeprops={'linewidth': 1, 'edgecolor': 'white'})\n",
    "    ax8.set_title('Win/Loss Ratio', fontsize=12)\n",
    "    \n",
    "    # --- (8) Performance Summary Text ---\n",
    "    ax9 = plt.subplot(gs[6, 1])\n",
    "    ax9.axis('off')  # Hide the axes for a text box\n",
    "    final_balance = portfolio[-1]\n",
    "    total_return = ((final_balance / initial_balance) - 1) * 100\n",
    "    summary_text = (\n",
    "        f\"{name} Performance Summary:\\n\\n\"\n",
    "        f\"Initial Balance: ${initial_balance:,.2f}\\n\"\n",
    "        f\"Final Balance:   ${final_balance:,.2f}\\n\"\n",
    "        f\"Total Return:    {total_return:.2f}%\\n\"\n",
    "        f\"Max Drawdown:    {max(drawdowns) * 100:.1f}%\\n\"\n",
    "        f\"Win Rate:        {win_rate:.1%}\\n\"\n",
    "        f\"Total Trades:    {len(trades)//2}\"\n",
    "    )\n",
    "    ax9.text(0.5, 0.5, summary_text, horizontalalignment='center', \n",
    "             verticalalignment='center', fontsize=12)\n",
    "    \n",
    "    # Print the performance summary to the console as well\n",
    "    print(summary_text)\n",
    "    \n",
    "    # Optional: Add interactive hover on the pie chart (if desired)\n",
    "    mplcursors.cursor(ax8, hover=True)\n",
    "    \n",
    "    # Adjust spacing and display the figure\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cdf03f-b922-4ae8-906a-3158cc40de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bt = Backtester(initial_balance=3000)\n",
    "    trades, portfolio = bt.run(test_df, model, features)\n",
    "    \n",
    "    drawdown_series = pd.Series(bt.drawdown_history, index=test_df.index)\n",
    "    \n",
    "    plot_strategy_analysis(\n",
    "        name=f\"{TICKER} ML Strategy\",\n",
    "        trades=trades,\n",
    "        portfolio=portfolio,\n",
    "        drawdowns=drawdown_series.tolist(),\n",
    "        data=df_features,  \n",
    "        initial_balance=3000\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nExecution error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0bf216-f7e3-4b2a-9c0d-0e56f7bd0713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
